{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualización en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import animation\n",
    "from functools import partial\n",
    "slider_layout = widgets.Layout(width='600px', height='20px')\n",
    "slider_style = {'description_width': 'initial'}\n",
    "IntSlider_nice = partial(widgets.IntSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "FloatSlider_nice = partial(widgets.FloatSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "SelSlider_nice = partial(widgets.SelectionSlider, style=slider_style, layout=slider_layout, continuous_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material teórico\n",
    "\n",
    "[Slides](https://docs.google.com/presentation/d/1IJ2n8X4w8pvzNLmpJB-ms6-GDHWthfsJTFuyUqHfXg8/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento digital de imágenes: Convolución\n",
    "\n",
    "Una imagen es una colección de pixeles ordenados\n",
    "\n",
    "En estándar RGB cada pixel corresponde a 3 valores enteros de 8 bit (256 niveles). Combinándolos formamos colores (aproximadamente 16.7M)\n",
    "\n",
    "Otra codificación usual para los pixeles consiste en usar un número entre cero y uno para cada canal (color)\n",
    "\n",
    "El estándar RGBA añade un canal que representa la opacidad\n",
    "\n",
    "Las imágenes en escala de grises y sin opacidad se pueden representar usando un canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('cameraman.png')\n",
    "img_bw = 0.2989*img[:, :, 0] + 0.587*img[:, :, 1]+ 0.114*img[:, :, 2]\n",
    "\n",
    "display(img_bw.shape)\n",
    "display(img_bw.dtype)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img_bw, cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestros sistemas digitales una imagen es una arreglo multidimensional y podemos operarlo como tal\n",
    "\n",
    "A que corresponde este segmento del arreglo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subimg = np.copy(img_bw[50:100, 120:180])\n",
    "display(subimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(subimg, cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una herramienta clásica de procesamiento digital de señales es la **convolución**\n",
    "\n",
    "La operación de convolución entre dos señales bidimensionales es\n",
    "\n",
    "$$\n",
    "(I_1 * I_2) [n_1, n_2] = \\sum_{m_1=-\\infty}^\\infty \\sum_{m_2=-\\infty}^\\infty I_1[m_1, m_2] I_2[n_1-m_2, n_2 - m_2]\n",
    "$$\n",
    "\n",
    "donde $n_1$ es el índice de las filas y $n_2$ es el índice de las columnas\n",
    "\n",
    "#### La convolución entre dos imágenes es una nueva imagen\n",
    "\n",
    "En la práctica los valores de $m_1$ y $m_2$ no pueden variar hasta infinito: *padding*\n",
    "\n",
    "¿Cómo se ve esta operación graficamente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado con convoluciones\n",
    "\n",
    "Un uso típico de la convolución es el filtrado\n",
    "\n",
    "La imagen $I_1$ es la entrada\n",
    "\n",
    "La imagen $I_2$ se denomina filtro o kernel de la convolución\n",
    "\n",
    "La imagen resultante es la imagen filtrada\n",
    "\n",
    "En la imagen filtrada se..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "filt = np.zeros(shape=(D, D))\n",
    "filt[1:-1, 1:-1] = 1\n",
    "img_res = scipy.signal.correlate2d(subimg, filt/np.sum(filt), mode='valid')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8, 3), tight_layout=True)\n",
    "ax[0].imshow(subimg, cmap=plt.cm.Greys_r)\n",
    "ax[1].imshow(filt, cmap=plt.cm.Greys_r)\n",
    "ax[2].imshow(img_res, cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro pasa-alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filt = [[1., -1.]]*2\n",
    "display(filt)\n",
    "img_res = scipy.signal.correlate2d(subimg, filt, mode='valid')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8, 3), tight_layout=True)\n",
    "ax[0].imshow(subimg, cmap=plt.cm.Greys_r)\n",
    "ax[1].imshow(filt, cmap=plt.cm.Greys_r)\n",
    "ax[2].imshow(img_res, cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detector de patillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = np.ones(shape=(11, 11))\n",
    "filt[:9, 2:9] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_res = scipy.signal.correlate2d(subimg, filt-np.mean(filt), mode='valid')\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 3), tight_layout=True)\n",
    "ax[0].imshow(subimg, cmap=plt.cm.Greys_r)\n",
    "maxloc = np.unravel_index(np.argmax(img_res), shape=img_res.shape)\n",
    "ax[0].scatter(maxloc[1]+filt.shape[0]//2, maxloc[0]+filt.shape[1]//2, c='r', s=20)\n",
    "ax[1].imshow(img_res, cmap=plt.cm.Reds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detector de cabezas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "img_res = scipy.signal.correlate2d(img_bw, subimg-np.mean(subimg), mode='valid')\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 3), tight_layout=True)\n",
    "ax[0].imshow(img_bw, cmap=plt.cm.Greys_r)\n",
    "maxloc = np.unravel_index(np.argmax(img_res), shape=img_res.shape)\n",
    "ax[0].scatter(maxloc[1]+subimg.shape[0]//2, maxloc[0]+subimg.shape[1]//2, c='r', s=20)\n",
    "ax[1].imshow(img_res, cmap=plt.cm.Reds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "filtro = np.array([[1., -1]]).T\n",
    "filtro = np.ones(shape=(6, 6))\n",
    "#filtro = np.zeros(shape=(28, 28)); \n",
    "#X, Y = np.meshgrid(np.arange(filtro.shape[0]), np.arange(filtro.shape[1]))\n",
    "#filtro[((X-14)**2 + (Y-14)**2 > 5**2) & ((X-14)**2 + (Y-14)**2 < 7**2) ] = 1\n",
    "if np.sum(filtro) > 0:\n",
    "    filtro = filtro/np.sum(filtro)\n",
    "\n",
    "fig, ax = plt.subplots(2, 11, figsize=(12, 6), tight_layout=True)\n",
    "for k in range(10):\n",
    "    image, label = mnist_train_data[k]\n",
    "    np_image = image.numpy()[0, :, :]\n",
    "    cv_image = np.absolute(scipy.signal.convolve2d(np_image, filtro, mode='valid'))\n",
    "    ax[1, k].imshow(cv_image, cmap=plt.cm.Greys_r, vmin=0, vmax=1)\n",
    "    ax[1, k].axis('off'); ax[0, k].axis('off');\n",
    "    ax[0, k].set_title(label)\n",
    "    ax[0, k].imshow(np_image, cmap=plt.cm.Greys_r)\n",
    "    \n",
    "ax[0, 10].axis('off')\n",
    "ax[1, 10].axis('off')\n",
    "ax[1, 10].imshow(filtro, cmap=plt.cm.RdBu_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal Convolucional en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data = torchvision.datasets.MNIST('dataset', train=True, download=True, \n",
    "                                              transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "image, label = mnist_train_data[0]\n",
    "display(len(mnist_train_data), type(image), type(label))\n",
    "fig, ax = plt.subplots(1, 10, figsize=(8, 2), tight_layout=True)\n",
    "for k in range(10):\n",
    "    image, label = mnist_train_data[k]\n",
    "    ax[k].imshow(image.numpy()[0, :, :], cmap=plt.cm.Greys_r)\n",
    "    ax[k].axis('off');\n",
    "    ax[k].set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferencia de Aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localización y segmentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
