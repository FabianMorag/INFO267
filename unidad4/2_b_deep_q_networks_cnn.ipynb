{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualización en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "torch.set_num_threads(8)\n",
    "torch.set_num_interop_threads(8)\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN a partir de píxeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación entrenaremos una Deep Q network para jugar *Space invaders* a partir de imágenes\n",
    "\n",
    "El ambiante de Open AI es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "#env = gym.make(\"SpaceInvaders-v0\") \n",
    "env = gym.make(\"PongNoFrameskip-v4\")\n",
    "state = env.reset()\n",
    "\n",
    "display(state.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 4), tight_layout=True)\n",
    "ax.axis('off')\n",
    "ax.imshow(state);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que el estado es una imagen de 210 x 160 x 3 pixeles\n",
    "\n",
    "En primer lugar haremos un preprocesamiento simple \n",
    "1. Combinar los canales en una imagen en blanco y negro\n",
    "1. Reescalar a 110x84 píxeles\n",
    "1. Convertir los pixeles a float y normalizar al rango [0, 1]\n",
    "1. Crear un stack de cuatro frames\n",
    "\n",
    "Para esto usaremos la librería *torchvision*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torchvision\n",
    "\n",
    "#env = gym.make(\"SpaceInvaders-v0\") \n",
    "env = gym.make(\"PongNoFrameskip-v4\")\n",
    "# Acumular 4 frames\n",
    "states = []\n",
    "states.append(env.reset())\n",
    "for k in range(3):    \n",
    "    a = env.action_space.sample()\n",
    "    s, r, end, info = env.step(a)\n",
    "    states.append(s)\n",
    "\n",
    "# Crear composición de transformaciones\n",
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToPILImage(),\n",
    "                                             torchvision.transforms.Grayscale(),\n",
    "                                             torchvision.transforms.Resize(size=(110, 84)),\n",
    "                                             torchvision.transforms.CenterCrop((84,84)),\n",
    "                                             torchvision.transforms.ToTensor()])\n",
    "# Función de para preprocesar\n",
    "def preprocess(states):\n",
    "    tmp = []\n",
    "    for state in states:\n",
    "        tmp.append(transforms(state))\n",
    "    return torch.cat(tmp) # Esto es un tensor de 1x4x210x160\n",
    "\n",
    "transformed_state = preprocess(states)\n",
    "display(\"Tamaño del tensor transformado:\", transformed_state.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(8, 2), tight_layout=True)\n",
    "for k in range(4):\n",
    "    ax[k].matshow(transformed_state[k, :, :].numpy(), cmap=plt.cm.Greys_r);\n",
    "    ax[k].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frame skipping\n",
    "\n",
    "Usaremos la técnica propuesta en (Minh et al 2013) conocida como *frame skipping*. Utilizamos 4 frames como estado pero ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(torch.nn.Module):    \n",
    "    def __init__(self, n_input, n_output, n_filters=32, n_hidden=256):\n",
    "        super(type(self), self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(n_input, n_filters, kernel_size=8, stride=4)\n",
    "        self.conv2 = torch.nn.Conv2d(n_filters, n_filters, kernel_size=4, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(n_filters, n_filters, kernel_size=3, stride=1)\n",
    "        self.linear1 = torch.nn.Linear(7 * 7 * n_filters, n_hidden)\n",
    "        self.output = torch.nn.Linear(n_hidden, n_output)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.activation(self.conv1(x))\n",
    "        h = self.activation(self.conv2(h))\n",
    "        h = self.activation(self.conv3(h))\n",
    "        h = h.view(-1, 7*7*32)\n",
    "        h = self.activation(self.linear1(h))\n",
    "        return  self.output(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve\n",
    "\n",
    "fig, ax = plt.subplots(4, figsize=(6, 5), sharex=True, tight_layout=True)\n",
    "\n",
    "def smooth_data(x, window_length=10):\n",
    "    return convolve(x, np.ones(window_length)/window_length, mode='valid')\n",
    "\n",
    "def update_plot(step, episode, smooth_window=10, target=195, target_update=500):\n",
    "    for ax_ in ax:\n",
    "        ax_.cla()\n",
    "    episodes = np.arange((episode))\n",
    "    ax[0].scatter(episodes, diagnostics['rewards'], s=1)      \n",
    "    if episode > smooth_window:\n",
    "        ax[0].plot(episodes[:-smooth_window+1], \n",
    "                   smooth_data(diagnostics['rewards']), alpha=0.5, lw=2)        \n",
    "    ax[1].plot(episodes, diagnostics['loss'])\n",
    "    ax[2].plot(episodes, np.array(diagnostics['q_sum'])/(np.array(diagnostics['q_N'])+1e-4))\n",
    "                   \n",
    "    #ax[0].plot(episodes, [target]*len(episodes), 'k--')\n",
    "    ax[0].set_ylabel('Recompensa');\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[2].set_ylabel('Q promedio')\n",
    "    ax[3].plot(episodes, epsilon(episodes))\n",
    "    ax[3].set_ylabel('Epsilon')\n",
    "    ax[3].set_xlabel('Episodios')\n",
    "    ax[0].set_title(\"Paso %d\" % (step))\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "env = gym.make(\"SpaceInvaders-v0\") \n",
    "n_state = (4, 110, 84)\n",
    "n_action = env.action_space.n \n",
    "\n",
    "dqn_model = DeepQNetwork(q_model=ConvolutionalNeuralNetwork(n_state[0], n_action),\n",
    "                         gamma = 0.99,\n",
    "                         double_dqn=True,\n",
    "                         target_update_freq=100,\n",
    "                         learning_rate=1e-4)\n",
    "\n",
    "def epsilon(episode, epsilon_init=1., epsilon_end=0.1, epsilon_rate=1e-2):\n",
    "    return epsilon_end + (epsilon_init - epsilon_end) * np.exp(-epsilon_rate*episode) \n",
    "\n",
    "memory = ReplayMemory(n_state, memory_length=10000)        \n",
    "\n",
    "diagnostics = {'rewards': [0], 'loss': [0],\n",
    "               'q_sum': [0], 'q_N': [0]}\n",
    "\n",
    "episode = 1\n",
    "end = False\n",
    "stacked_states = []\n",
    "stacked_states.append(env.reset())\n",
    "for k in range(3):\n",
    "    s, r, end, info = env.step(0)  \n",
    "    stacked_states.append(s)\n",
    "\n",
    "for step in tqdm(range(100000)):    \n",
    "    # Escoger acción\n",
    "    state = preprocess(stacked_states)\n",
    "    a, q = dqn_model.select_action(state.unsqueeze(0), epsilon(episode))\n",
    "    if q is not None:\n",
    "        diagnostics['q_sum'][-1] += q\n",
    "        diagnostics['q_N'][-1] += 1\n",
    "    \n",
    "    # Aplicar la acción y guardar 4 fames\n",
    "    stacked_states_next = []\n",
    "    r = 0.0\n",
    "    end = False\n",
    "    for k in range(4):\n",
    "        s, r_tmp, end_tmp, info = env.step(a)        \n",
    "        stacked_states_next.append(s)\n",
    "        end  = end | end_tmp\n",
    "        r += r_tmp\n",
    "    diagnostics['rewards'][-1] += r\n",
    "               \n",
    "    # Guardar en memoria\n",
    "    memory.push(state, preprocess(stacked_states_next), \n",
    "                a, torch.tensor(r), end)\n",
    "    \n",
    "    stacked_states = stacked_states_next\n",
    "    \n",
    "    # Actualizar modelo    \n",
    "    mini_batch = memory.sample(32)\n",
    "    if not mini_batch is None:\n",
    "        diagnostics['loss'][-1] += dqn_model.update(mini_batch)            \n",
    "    \n",
    "    # Preparar siguiente episodio\n",
    "    if end:\n",
    "        if episode % 5 == 0:\n",
    "            update_plot(step, episode)\n",
    "        episode += 1   \n",
    "        end = False\n",
    "        stacked_states = []\n",
    "        stacked_states.append(env.reset())\n",
    "        for k in range(3):\n",
    "            s, r, end, info = env.step(0)  \n",
    "            stacked_states.append(s)\n",
    "        diagnostics['rewards'].append(0)\n",
    "        diagnostics['loss'].append(0)\n",
    "        diagnostics['q_sum'].append(0)\n",
    "        diagnostics['q_N'].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from time import sleep\n",
    "\n",
    "env = gym.make(\"SpaceInvaders-v0\") \n",
    "env.reset()\n",
    "end = False\n",
    "\n",
    "stacked_states = []\n",
    "stacked_states.append(env.reset())\n",
    "for k in range(3):\n",
    "    s, r, end, info = env.step(0)  \n",
    "    stacked_states.append(s)\n",
    "\n",
    "while not end:\n",
    "    state = preprocess(stacked_states)\n",
    "    a, q = dqn_model.select_action(state.unsqueeze(0))\n",
    "    print(a)\n",
    "    #stacked_states = []\n",
    "    #for k in range(4):\n",
    "    #    s, r, end, info = env.step(a)  \n",
    "    #    stacked_states.append(s)\n",
    "    s, r, end, info = env.step(a)\n",
    "    stacked_states = stacked_states[1:]\n",
    "    stacked_states.append(s)\n",
    "    #env.render() \n",
    "    sleep(.02)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from time import sleep\n",
    "from IPython import display\n",
    "\n",
    "env = gym.make(\"SpaceInvaders-v0\") \n",
    "env.reset()\n",
    "end = False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "stacked_states = []\n",
    "stacked_states.append(env.reset())\n",
    "for k in range(3):\n",
    "    s, r, end, info = env.step(0)  \n",
    "    stacked_states.append(s)\n",
    "\n",
    "while not end:\n",
    "    \n",
    "    state = preprocess(stacked_states)\n",
    "    a, q = dqn_model.select_action(state.unsqueeze(0))\n",
    "    s, r, end, info = env.step(a)\n",
    "    stacked_states = stacked_states[1:]\n",
    "    stacked_states.append(s)\n",
    "    \n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    \n",
    "    #sleep(.02)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
