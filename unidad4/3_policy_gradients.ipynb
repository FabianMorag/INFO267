{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy learning\n",
    "\n",
    "Find $\\pi(s)$, sample $a\\sim\\pi(s)$\n",
    "\n",
    "Neural network that recieves a state and returns $P(a_1|s), P(a_2|s), \\ldots, P(a_N|s)$. You draw a sample from this distribution\n",
    "\n",
    "advantages? distribution does not need to be categorical, can handle continuous, parametrize $\\mu$ and $\\sigma$ \n",
    "\n",
    "\n",
    "Training algorithm\n",
    "\n",
    "- Run policy until termination, record tuples actions/states/rewards\n",
    "- Decrease pbb of actions that ended on low reward \n",
    "- Increase pbb of actions that ended on high reward\n",
    "\n",
    "$$\n",
    "L = - \\log P(a_t|s_t) R_t\n",
    "$$\n",
    "\n",
    "log likelihood of selecting the action, how likely was this action that you selected\n",
    "\n",
    "total discounted returned recieved by selecting that action\n",
    "\n",
    "- high reward times likely action -> desirable, will not change\n",
    "- reward is low times likely action -> undesirable, will minimize: remove pbb of this action\n",
    "\n",
    "$$\n",
    "w = w + \\mu \\nabla \\log P(a_t|s_t) R_t\n",
    "$$\n",
    "\n",
    "policy gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "real life: run until termination!!!!! Requires simulator!!!!\n",
    "- realistic simulation + transfer learning\n",
    "- real world observations + one shot trial & error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1811.12560.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/PacktPublishing/PyTorch-1.x-Reinforcement-Learning-Cookbook/tree/master/Chapter07/chapter7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starcraft 2:\n",
    "\n",
    "- https://github.com/deepmind/pysc2\n",
    "- http://chris-chris.ai/2017/08/30/pysc2-tutorial1/\n",
    "- https://github.com/chris-chris/pysc2-examples\n",
    "- https://blog.goodaudience.com/lessons-and-mistakes-from-my-first-reinforcement-learning-starcraft-agent-4245cc35e956\n",
    "- https://faculty.utrgv.edu/dongchul.kim/csci4352/spring2019/report/R5.pdf\n",
    "- http://courses.cecs.anu.edu.au/courses/CSPROJECTS/19S1/reports/u6049249_report.pdf\n",
    "- https://chatbotslife.com/building-a-smart-pysc2-agent-cdc269cb095d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
